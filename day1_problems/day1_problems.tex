\documentclass[aps,prd,superscriptaddress,groupedaddress,nofootinbib,nobibnotes]{revtex4}

\usepackage{graphicx}
\usepackage{dcolumn}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{color}
\usepackage{mathrsfs}
% \usepackage{comment}
% \usepackage{url}
% \usepackage{wick}
% \usepackage{feynmp}
% \usepackage{braket}

\setlength{\parindent}{20pt}
% \setlength{\parskip}{1mm}

\setcounter{topnumber}{1}    % default value is 2.
\setcounter{bottomnumber}{0} % default value is 1.

\hyphenation{ALPGEN}
\hyphenation{EVTGEN}
\hyphenation{PYTHIA}

\newcommand{\kms}[1]{\textcolor{blue}{(KMS: #1)}}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\ba}{\begin{eqnarray}}
\newcommand{\ea}{\end{eqnarray}}
\newcommand{\nn}{\nonumber}
\newcommand{\barr}{\begin{array}}
\newcommand{\earr}{\end{array}}
\newcommand{\eqdef}{\stackrel{\rm def}{=}}
\newcommand{\bigoh}{\mathcal{O}}

\newcommand\lsim{\mathrel{\rlap{\lower4pt\hbox{\hskip1pt$\sim$}}
        \raise1pt\hbox{$<$}}}
\newcommand\gsim{\mathrel{\rlap{\lower4pt\hbox{\hskip1pt$\sim$}}
        \raise1pt\hbox{$>$}}}

\def\threej#1#2#3#4#5#6{\left( \begin{array}{ccc} #1 & #2 & #3 \\ #4 & #5 & #6 \end{array} \right) }
\def\smallsum{\mathop{\textstyle\sum}\limits}
\def\Var{\mbox{Var}}
\def\Cov{\mbox{Cov}}

\renewcommand{\baselinestretch}{1.1}

\begin{document}

\title{Problems: Gaussian random variables and a little bit of linear algebra}

\author{ISSYP 2016}
% \affiliation{Perimeter Institute for Theoretical Physics, Waterloo, ON N2L 2Y5, Canada}
% \date{\today}

% \begin{abstract}
% ABSTRACT HERE
% \end{abstract}
% \pacs{}

\maketitle

\begin{enumerate}

\item {\em Mean and variance for biased coin flips.}
Assume the following properties of random variables:
\ba
\langle X_1 + X_2 \rangle &=& \langle X_1 \rangle + \langle X_2 \rangle \hspace{1cm} \mbox{always} \nn \\
\langle c X \rangle &=& c \langle X \rangle \hspace{2.15cm} \mbox{if $c$ is constant (i.e.~not a random variable)} \nn \\
\langle X_1 X_2 \rangle &=& \langle X_1 \rangle \, \langle X_2 \rangle \hspace{1.37cm} \mbox{if $X_1,X_2$ are independent random variables}
\ea
(a) Using these properties, show that if $X = X_1 + X_2$, where $X_1,X_2$ are independent random variables, then $\Var(X) = \Var(X_1) + \Var(X_2)$.
\par\medskip
(b) Consider a biased coin which is heads with probability $p$, and tails with probability $(1-p)$.
Let $H_1$ be the number of heads after a single flip (either 0 or 1).  What are the mean and variance of the random variable $H_1$?
Let $H_N$ be the number of heads after $N$ flips.  What are the mean and variance of $H_N$?

\item {\em A toy example of the central limit theorem.}
Define a random variable $X$ by generating a random number $\theta$ between 0 and $2\pi$, and
then setting $X = \cos(\theta)$.
\par\medskip
(a) Compute the mean $\bar X$ and variance $\Var(X)$ analytically.  Hint: these can be written as integrals over $\theta$.
\par\medskip
(b) Now suppose we define a random variable $Z_N = (X_1 + \cdots + X_N) / N^{1/2}$.  In the limit of large $N$,
what probability distribution $p(Z_N)$ is predicted by the central limit theorem?
\par\medskip
(c) Computer exercise: in a programming language of your choice, write a function which makes a random realization of the
random variable $X$, and the random variable $Z_{20}$.  By simulating many $X$'s and taking an appropriate average, show 
that the mean and variance agree with what you calculated in part (a).  By simulating many $Z_{20}$'s and making a histogram,
show that the probability distribution agrees with what you calculated in part (b).

\item {\em Gaussian integrals.} (Warning: hard!) In this problem, you can assume that:
\be
\int_{-\infty}^\infty dx \, e^{-x^2} = \sqrt{\pi}
\ee
(If you're curious how this is shown, there is a famous trick which is explained in the appendix!)
\par\medskip
(a) By change of variable show that
\be
\int_{-\infty}^\infty dx \, e^{-ax^2} = \sqrt{\pi} a^{-1/2}  \label{eq:gaussian_a}
\ee
where $a > 0$ is a real number.
\par\medskip
(b) Now show that 
\be
\int_{-\infty}^\infty dx \, x^2 e^{-ax^2} = \frac{\sqrt{\pi}}{2} a^{-3/2}   \label{eq:gaussian_a2}
\ee
using one of two possible approaches.  One way is to group the integrand on the LHS as $(x) (x e^{-ax^2})$
and use integration by parts.  The second way is to differentiate both sides of Eq.~(\ref{eq:gaussian_a})
with respect to $a$.
\par\medskip
(c) Using the previous results show that the Gaussian probability distribution in one variable
\be
p(x) = \frac{1}{(2\pi)^{1/2} \sigma} \exp\left( - \frac{x^2}{2\sigma^2} \right)
\ee
is correctly normalized (i.e.~$\int p(x) = 1$) with variance $\sigma^2$ 
(i.e.~$\int x^2 p(x) = \sigma^2$), as implicitly assumed in the lecture.
\par\medskip
(d) Can you generalize part (b) to give a formula for $\int x^N e^{-ax^2}$, where $N$ is a positive integer?

\end{enumerate}


%\begin{figure}
%\centerline{\includegraphics[width=14cm]{x.pdf}}
%\caption{xxx}
%\label{fig:xxx}
%\end{figure}

% \section*{Acknowledgments}
%
% Research at Perimeter Institute is supported by the Government of Canada
% through Industry Canada and by the Province of Ontario through the Ministry of Research \& Innovation.
% Some computations were performed on the GPC cluster at the SciNet HPC Consortium.
% SciNet is funded by the Canada Foundation for Innovation under the auspices of Compute Canada,
% the Government of Ontario, and the University of Toronto.
% KMS was supported by an NSERC Discovery Grant and an Ontario Early Researcher Award.

% \bibliographystyle{h-physrev}
% \bibliography{xxx}

\appendix
\section{A famous trick for calculating $\int_{-\infty}^\infty dx e^{-x^2}$}

\par\noindent
As far as I know, the following strange trick is the only way of doing the integral!
You'll need to have studied a little bit of multivariate calculus, in particular changing variables from
Cartesian to polar coordinates in a 2D integral.
Define:
\be
I = \int_{-\infty}^\infty dx \, e^{-x^2}
\ee
We can write $I^2$ as a 2D integral over the $(x,y)$ plane.
\ba
I^2 &=& \left( \int_{-\infty}^\infty dx \, e^{-x^2} \right) \left( \int_{-\infty}^\infty dy \, e^{-y^2} \right)  \nn \\
  &=& \int \int dx\, dy \, e^{-x^2-y^2}
\ea
This doesn't appear to be making progress, but if we now change variables to polar coordinates $(r,\theta)$,
then we can do the integral!  (In the steps below, we integrate over $\theta$ first and then $r$.)
\ba
I^2 &=& \int dr \, d\theta \, r e^{-r^2}  \nn \\
    &=& 2 \pi \int_0^\infty dr \, r e^{-r^2} \nn \\
    &=& 2 \pi \left( \frac{1}{2} \right)
\ea
Note that the extra factor of $r$ we picked up in the change of variables to polar coordinates is what
allows us to do the integral.  Taking the square root on both sides we now get $I = \sqrt{\pi}$ as desired.

\end{document}
